{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "from typing import Optional, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "from config import config\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train function\n",
    "from akrmap import train_parametric_akr_map_model\n",
    "from akrmap.akr_model import NeuralMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([430000, 2048])\n",
      "torch.Size([430000])\n"
     ]
    }
   ],
   "source": [
    "#import \n",
    "import numpy as np\n",
    "txt_features0=np.load(\"data/HPSv2_all_train_txt.npy\")\n",
    "txt_features1=np.load(\"data/HPSv2_all_train_img.npy\")\n",
    "txt_features=torch.Tensor(np.concatenate([txt_features0,txt_features1],axis=1)).to(\"cuda\")[:430000]\n",
    "scores=torch.Tensor(100*np.sum(txt_features0*txt_features1, axis=1)).to(\"cuda\")[:430000]\n",
    "scores=scores.reshape((scores.shape[0],))\n",
    "print(txt_features.shape)\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 430/430 [02:11<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1. Time 0:02:11.884414. Average loss: 1.8743\n",
      "====> Epoch: 1. Time 0:02:11.884414. Average Map loss: 1.9220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1: 0.9992773532867432\n",
      "a2: 1.5346351861953735\n",
      "b: 1.446234107017517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 430/430 [02:07<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2. Time 0:02:07.716541. Average loss: 1.6746\n",
      "====> Epoch: 2. Time 0:02:07.716541. Average Map loss: 1.4618\n",
      "a1: 0.9991363883018494\n",
      "a2: 1.8417285680770874\n",
      "b: 1.530693769454956\n",
      "Loss history saved in akrmaptsne_oqimai_epoch_2_loss.npy\n",
      "final kernel params\n",
      "a1: 0.9991363883018494\n",
      "a2: 1.8417285680770874\n",
      "b: 1.530693769454956\n",
      "Training time: 0:04:19.604466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train projection models\n",
    "dim_input=txt_features.shape[1]\n",
    "model_path, a1, a2, b=train_parametric_akr_map_model(txt_features, dim_input, config, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained model\n",
    "a1= 0.9987241625785828\n",
    "a2= 7.954826354980469\n",
    "b= 1.1770744323730469\n",
    "model_path=\"saved_models/Text-to-image/HPSv2_HPD\"\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_weights=model_path+\".pt\"\n",
    "loaded_model = torch.load(model_weights, weights_only=False).to(dev)\n",
    "bs = config.training_params[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling function for fast kernel estimate\n",
    "import random\n",
    "\n",
    "def kernel_sample_and_get_remaining_ids(N, n, seed=None):\n",
    "    # Ensure n is not larger than N\n",
    "    if n > N:\n",
    "        raise ValueError(\"n cannot be larger than N\")\n",
    "    \n",
    "    # Set the random seed if provided\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    sampled_ids = random.sample(range(N), n)\n",
    "    sampled_set = set(sampled_ids)\n",
    "    return sampled_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([430000])\n",
      "torch.Size([430000, 1])\n",
      "projected_pos (430000, 2)\n"
     ]
    }
   ],
   "source": [
    "#project embeddings\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "labels_train=torch.tensor(np.array([1 for i in range(len(txt_features))])).to(\"cuda\")\n",
    "print(labels_train.shape)\n",
    "labels_train=labels_train.reshape((labels_train.shape[0],1))\n",
    "print(labels_train.shape)\n",
    "points_train_ds = TensorDataset(txt_features, labels_train)\n",
    "def get_batch_embeddings(pretrained_model: torch.nn.Module,\n",
    "                         input_points: Dataset,\n",
    "                         batch_size: int):\n",
    "    \"\"\"\n",
    "    Yields final embeddings for every batch in dataset\n",
    "    \"\"\"\n",
    "    pretrained_model.eval()\n",
    "    test_dl = DataLoader(input_points, batch_size=batch_size, shuffle=False)\n",
    "    for batch_points, batch_labels in test_dl:\n",
    "        with torch.no_grad():\n",
    "            embeddings = pretrained_model(batch_points)\n",
    "            yield embeddings, batch_labels\n",
    "\n",
    "pretrained_model=loaded_model\n",
    "input_points_train=points_train_ds\n",
    "batch_size=bs\n",
    "pos_list=[]\n",
    "for embeddings, batch_labels in get_batch_embeddings(pretrained_model,\n",
    "                                                     input_points_train,\n",
    "                                                     batch_size):\n",
    "    x1 = embeddings[:, 0].detach().cpu().numpy()\n",
    "    x2 = embeddings[:, 1].detach().cpu().numpy()\n",
    "    pos_list.append(embeddings.detach().cpu().numpy())\n",
    "\n",
    "projected_pos=np.concatenate(pos_list)\n",
    "print(\"projected_pos\", projected_pos.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define kernel regression function\n",
    "def compute_kde_regression_new(X, Y, z_arr, a1, a2, b, h):\n",
    "    n, d= X.shape\n",
    "    a1 = torch.tensor(a1, dtype=torch.float32, device=dev)\n",
    "    a2 = torch.tensor(a2, dtype=torch.float32, device=dev)\n",
    "    b = torch.tensor(b, dtype=torch.float32, device=dev)\n",
    "    X = torch.tensor(X, dtype=torch.float32, device=dev)\n",
    "    Y = torch.tensor(Y, dtype=torch.float32, device=dev)\n",
    "    dists = torch.cdist(X, Y)\n",
    "    ra2=a2**2\n",
    "    ra1=a1**2\n",
    "    rb=b**2\n",
    "    kernels=1/(1+ra2*dists**(2*rb))\n",
    "\n",
    "    w_kde=z_arr @ (kernels)\n",
    "    kde=torch.sum(kernels, axis=0)\n",
    "    kde_reg=w_kde/kde\n",
    "    return (ra1*kde_reg).detach().cpu().numpy()\n",
    "\n",
    "def compute_kde_regression_baseline(X, Y, z_arr, a1=1, a2=1, b=1, h=0.9):\n",
    "    n, d= X.shape\n",
    "    a1 = torch.tensor(a1, dtype=torch.float32, device=\"cuda\")\n",
    "    a2 = torch.tensor(a2, dtype=torch.float32, device=\"cuda\")\n",
    "    b = torch.tensor(b, dtype=torch.float32, device=\"cuda\")\n",
    "    X = torch.tensor(X, dtype=torch.float32, device=\"cuda\")\n",
    "    Y = torch.tensor(Y, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    dists = torch.cdist(X, Y)\n",
    "    ra2=1\n",
    "    ra1=1\n",
    "    rb=1\n",
    "    w_kde=z_arr @ (torch.exp(-dists**(2)/((2 * h ** 2))))\n",
    "    kde=torch.sum(torch.exp(-dists**(2)/((2 * h ** 2))), axis=0)\n",
    "    kde_reg=w_kde/(kde+1e-20)\n",
    "    return (kde_reg).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50)\n",
      "21.3487 30.078835\n"
     ]
    }
   ],
   "source": [
    "# compute contour without border\n",
    "x_min, x_max=projected_pos.min(0), projected_pos.max(0)\n",
    "# grid=2000\n",
    "grid=50\n",
    "xi = np.linspace(x_min[0], x_max[0], grid)\n",
    "yi = np.linspace(x_min[1], x_max[1], grid)\n",
    "z_list=[]\n",
    "k_ids=kernel_sample_and_get_remaining_ids(len(txt_features),20000,seed=42)\n",
    "for i in range(len(xi)):\n",
    "    Y1=[]\n",
    "    for j in range(len(yi)):\n",
    "        Y1.append(np.array([xi[i],yi[j]]).reshape((1,2)))\n",
    "    Y1_array=np.concatenate(Y1, axis=0)\n",
    "    kde_y=compute_kde_regression_new(projected_pos[k_ids], Y1_array, scores[k_ids], a1, a2, b, 0.9)\n",
    "    z_list.append(kde_y.reshape((len(yi), 1)))\n",
    "  # print(kde_y.shape)\n",
    "zi=np.concatenate(z_list, axis=1)\n",
    "print(zi.shape)\n",
    "print(np.min(zi), np.max(zi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute contour with border\n",
    "from scipy.spatial import cKDTree\n",
    "# Define grid bounds from projected positions\n",
    "x_min, x_max = projected_pos.min(0), projected_pos.max(0)\n",
    "# x_min= x_min-0.05*(x_max-x_min)\n",
    "# x_max= x_max+0.05*(x_max-x_min)\n",
    "# Define grid resolution\n",
    "grid =1024\n",
    "xi = np.linspace(x_min[0], x_max[0], grid)\n",
    "yi = np.linspace(x_min[1], x_max[1], grid)\n",
    "\n",
    "# Compute distances of grid points to projected_pos\n",
    "X_grid, Y_grid = np.meshgrid(xi, yi)\n",
    "grid_points = np.vstack([X_grid.ravel(), Y_grid.ravel()]).T\n",
    "\n",
    "# Construct k-d tree and find nearest distances\n",
    "tree = cKDTree(projected_pos)\n",
    "distances, _ = tree.query(grid_points)\n",
    "\n",
    "# Reshape distances back to grid shape\n",
    "distance_grid = distances.reshape(grid, grid)\n",
    "\n",
    "# Set threshold for masking distant grid points\n",
    "threshold = 0.1*(x_max[0]-x_min[0])  # Adjust as needed\n",
    "\n",
    "# Compute KDE regression with distance-based masking\n",
    "z_list = []\n",
    "for i in range(len(xi)):\n",
    "    Y1 = np.array([[xi[i], y] for y in yi])  # Shape (grid, 2)\n",
    "    kde_y = compute_kde_regression_new(\n",
    "        projected_pos[k_ids], Y1, scores[k_ids], a1, a2, b, 0.9\n",
    "    )\n",
    "    z_list.append(kde_y.reshape((len(yi), 1)))\n",
    "\n",
    "zi = np.concatenate(z_list, axis=1)\n",
    "\n",
    "# Apply NaN mask\n",
    "zi[distance_grid > threshold] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display contour map\n",
    "fig, ax1 = plt.subplots(nrows=1, figsize=(9, 7))\n",
    "# Plot contour plot\n",
    "cntr1 = ax1.contourf(xi, yi, zi, levels=40, cmap='RdYlBu_r')\n",
    "fig.colorbar(cntr1, ax=ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Assume xi, yi, zi arrays are defined as in your original code\n",
    "# xi, yi are the grid coordinates, and zi is the contour data (same as cntr1 in Matplotlib)\n",
    "\n",
    "k_ids1=kernel_sample_and_get_remaining_ids(430000,2000,seed=42)\n",
    "df = pd.DataFrame(projected_pos[k_ids1], columns=['Dimension 1', 'Dimension 2'])\n",
    "df['Target'] = scores[k_ids1].detach().cpu().numpy()  # Add the target array to the DataFrame\n",
    "df['Id'] = k_ids1\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the contour plot (underlay)\n",
    "# fig.add_trace(go.Contour(\n",
    "#     z=zi,\n",
    "#     x=xi,  # x-coordinates of the grid\n",
    "#     y=yi,  # y-coordinates of the grid\n",
    "#     colorscale=\"GnBu\",      # Colormap\n",
    "#     contours=dict(start=zi.min(), end=zi.max(), size=(zi.max() - zi.min()) / 60),  # Match levels (60 in original code)\n",
    "#     showscale=False,        # Disable color bar for the contour layer\n",
    "#     opacity=0.7             # Make it partially transparent\n",
    "# ))\n",
    "fig.add_trace(go.Heatmap(\n",
    "    z=zi,\n",
    "    x=xi,\n",
    "    y=yi,\n",
    "    colorscale='RdYlBu_r',  # Colormap\n",
    "    showscale=False,    # Remove the color scale bar for the underlay (optional)\n",
    "    zsmooth='best'      # Smooth interpolation for the heatmap\n",
    "))\n",
    "\n",
    "hover_text = [\n",
    "    f\"Dimension 1: {x:.2f}<br>Dimension 2: {y:.2f}<br>Target: {t:.2f}<br>Id: {u:.2f}\"\n",
    "    for x, y, t, u in zip(df['Dimension 1'], df['Dimension 2'], df['Target'], df['Id'])\n",
    "]\n",
    "# Add the scatter plot (overlay)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df['Dimension 1'],\n",
    "    y=df['Dimension 2'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=20,                # Match point size\n",
    "        color=df['Target'],     # Color based on the target column\n",
    "        colorscale='RdYlBu_r',      # Match the colormap\n",
    "        line=dict(width=0.5, color='white'),  # White edges around each point\n",
    "        opacity=0.8             # Match transparency\n",
    "    ),\n",
    "    text=hover_text,  # Custom text for tooltips\n",
    "    hoverinfo='text',  # Use only the custom text in the tooltip\n",
    "))\n",
    "\n",
    "# Update layout for style consistency\n",
    "fig.update_layout(\n",
    "    title=\"Interactive Scatter Plot with Contour Underlay\",  # Add a title\n",
    "    xaxis_title=\"Dimension 1\",                               # X-axis label\n",
    "    yaxis_title=\"Dimension 2\",                               # Y-axis label\n",
    "    autosize=False,                                          # Disable automatic resizing\n",
    "    # width=900,                                               # Set figure width\n",
    "    # height=700,                                              # Set figure height\n",
    "    width=900,\n",
    "    height=900,  # Set figure size to be square\n",
    "    xaxis=dict(\n",
    "        scaleanchor=\"y\"  # Link x-axis scale to y-axis\n",
    "    ),\n",
    "    # xaxis=dict(scaleanchor='y'),                             # Fix aspect ratio 1:1\n",
    "    paper_bgcolor='white',                                   # Background color\n",
    "    plot_bgcolor='white',                                    # Plot area background\n",
    "    font=dict(size=12, color='black'),                       # Font settings\n",
    "    margin=dict(l=50, r=50, t=50, b=50),                     # Margins\n",
    ")\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
